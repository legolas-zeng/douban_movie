# encoding:UTF-8import reimport requestsimport MySQLdbfrom bs4 import BeautifulSoupheaders = {'User-Agent' :'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}def getPage(get_url):    r=requests.get(get_url)    response = r.text    return responsedef filterpage():    pageCode = getPage(get_url)    pattern = re.compile('<em class="">(.*?)</em>.*?<span class="title">(.*?)</span>.*?<span class="rating_num" property="v:average">(.*?)</span>',re.S)    items = re.findall(pattern,pageCode)    pageStories = []    for item in items:        pageStories.append([item[0].strip(),item[1].strip(),item[2].strip()])    return pageStoriesdef save_data():    Dbdata=filterpage()    db=MySQLdb.connect(host='localhost',user='root',passwd='suyu.123',db='movie',charset='utf8')    cursor=db.cursor()    for a in Dbdata:        id=a[0]        name=a[1]        grade=a[2]        #comment=a[3]        value=[id,name,grade]        cursor.execute('insert into movie_info values(%s,%s,%s)',value)        db.commit()def main():    pageStories=filterpage()    #print pageStories    for story in pageStories:        try:            print u"序号：",story[0],u"电影名：",story[1], u"\t评分：", story[2]        except:            passif __name__ == '__main__':    get_url = 'https://movie.douban.com/top250/'    i=1    while i < 11:        main()        save_data()        print u'页码',i+1        num = i * 25        get_url = 'https://movie.douban.com/top250?start=' + str(num) + '&filter='        i = i + 1